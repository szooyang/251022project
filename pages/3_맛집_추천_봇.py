# pages/3_ë§›ì§‘_ì¶”ì²œ_ë´‡.py
import time
import json
import re
import difflib
import requests
import pandas as pd
import streamlit as st
from urllib.parse import quote_plus

# ============== ê¸°ë³¸ ì„¸íŒ… ==============
st.set_page_config(page_title="ë§›ì§‘ ì¶”ì²œ ë´‡ â€“ ë¦¬ì–¼ì„œì¹˜", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” ë§›ì§‘ ì¶”ì²œ ë´‡ â€” ë¦¬ì–¼ì„œì¹˜ ê¸°ë°˜ (ê±°ì§“ ì œë¡œ ì§€í–¥)")
st.caption("ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ë¡œë§Œ ì¶”ì²œí•©ë‹ˆë‹¤. (ì¹´ì¹´ì˜¤ í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í‚¤ ì—†ì´ë„ ë™ì‘)")

OPENAI_KEY = st.secrets.get("OPENAI_API_KEY", "")
KAKAO_KEY  = st.secrets.get("KAKAO_REST_KEY", "")

# OpenAI (ìš”ì•½/ì½”ë©˜íŠ¸ ì „ìš©)
try:
    from openai import OpenAI
    _openai_ok = True
except Exception:
    _openai_ok = False

# ============== ì»¨íŠ¸ë¡¤ ==============
default_food = st.session_state.get("selected_food", "")
SEOUL_GU = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬","ë…¸ì›êµ¬","ë„ë´‰êµ¬",
    "ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬","ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬",
    "ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]
c1, c2, c3 = st.columns([1,1,1])
with c1:
    gu = st.selectbox("ì„œìš¸ **êµ¬**", SEOUL_GU, index=SEOUL_GU.index("ê°•ë‚¨êµ¬"))
with c2:
    food = st.text_input("ìŒì‹/í‚¤ì›Œë“œ", value=str(default_food) or "ë¹„ë¹”ë°¥")
with c3:
    topk = st.slider("ìµœëŒ€ ì¶”ì²œ ìˆ˜", 3, 10, 5)

go = st.button("ì‹¤ì‹œê°„ìœ¼ë¡œ ì°¾ê¸° ğŸš€", use_container_width=True)
st.write("---")

# ============== ìˆ˜ì§‘ê¸° ==============

# 1) Kakao Local (ìˆìœ¼ë©´ ì‚¬ìš©)
KAKAO_URL = "https://dapi.kakao.com/v2/local/search/keyword.json"

def kakao_search_places(rest_key: str, gu: str, food: str, size: int):
    headers = {"Authorization": f"KakaoAK {rest_key}"}
    q = f"{gu} {food} ì‹ë‹¹"
    params = {"query": q, "category_group_code": "FD6", "size": size, "page": 1}
    r = requests.get(KAKAO_URL, headers=headers, params=params, timeout=10)
    r.raise_for_status()
    docs = r.json().get("documents", [])
    out = []
    for d in docs:
        out.append({
            "name": d.get("place_name",""),
            "road_address": d.get("road_address_name",""),
            "address": d.get("address_name",""),
            "phone": d.get("phone",""),
            "url": d.get("place_url",""),
            "lat": float(d["y"]) if d.get("y") else None,
            "lon": float(d["x"]) if d.get("x") else None,
            "source": "kakao"
        })
    return out

# 2) Overpass(í‚¤ ì—†ì´ í›„ë³´) â†’ í›„ê²€ì¦ìœ¼ë¡œ ì‹¤ì¡´ í•„í„°
OVERPASS = "https://overpass-api.de/api/interpreter"

def overpass_candidates(gu: str, food: str, size: int):
    food_esc = re.sub(r'(["\\])', r"\\\1", food)
    q = f"""
    [out:json][timeout:25];
    area["name:ko"="{gu}"]["boundary"="administrative"]["admin_level"="6"]->.a;
    (
      node["amenity"="restaurant"]["name:ko"~"{food_esc}", i](area.a);
      node["amenity"="restaurant"]["name"~"{food_esc}", i](area.a);
      node["amenity"="restaurant"]["cuisine"~"{food_esc}", i](area.a);
      way["amenity"="restaurant"]["name:ko"~"{food_esc}", i](area.a);
      way["amenity"="restaurant"]["name"~"{food_esc}", i](area.a);
      way["amenity"="restaurant"]["cuisine"~"{food_esc}", i](area.a);
    );
    out center {size*3};   /* ì—¬ìœ ë¡œ ê°€ì ¸ì™€ì„œ ê²€ì¦ë‹¨ê³„ì—ì„œ ì¶”ë¦¼ */
    """
    r = requests.post(OVERPASS, data={"data": q}, timeout=30)
    r.raise_for_status()
    elements = r.json().get("elements", [])
    out = []
    for el in elements:
        tags = el.get("tags", {})
        name = tags.get("name:ko") or tags.get("name") or ""
        addr = tags.get("addr:full") or " ".join(
            filter(None, [tags.get("addr:city"), tags.get("addr:district"),
                          tags.get("addr:street"), tags.get("addr:housenumber")])
        )
        lat = el.get("lat") or (el.get("center") or {}).get("lat")
        lon = el.get("lon") or (el.get("center") or {}).get("lon")
        if name and lat and lon:
            out.append({
                "name": name, "road_address": addr, "address": addr,
                "phone": "", "url": "", "lat": lat, "lon": lon, "source": "osm"
            })
    return out[: size*3]

# 3) ë„¤ì´ë²„ ì›¹ê²€ìƒ‰(ì¼ë°˜)ìœ¼ë¡œ ì‹¤ì¡´ ê²€ì¦
HEADERS = {
    "User-Agent": ("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/130.0.0.0 Safari/537.36")
}

def naver_web_validate(name: str, gu: str, food: str):
    """ë„¤ì´ë²„ ì¼ë°˜ ê²€ìƒ‰ ìƒìœ„ ê²°ê³¼ì—ì„œ ìƒí˜¸ í¬í•¨ ì—¬ë¶€ í™•ì¸ í›„ ë§í¬/íƒ€ì´í‹€/ìŠ¤ë‹ˆí« ë°˜í™˜"""
    q = f"{gu} {name} {food}"
    url = f"https://search.naver.com/search.naver?query={quote_plus(q)}"
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        r.raise_for_status()
    except Exception:
        return None

    # ë‹¨ìˆœ aíƒœê·¸ ì¶”ì¶œ + í•„í„°ë§
    titles, links = [], []
    for a in re.findall(r'<a[^>]+href="([^"]+)"[^>]*>(.*?)</a>', r.text, flags=re.I|re.S):
        href, title_html = a
        title = re.sub("<.*?>", "", title_html)
        if not title or not href.startswith("http"):
            continue
        # ë¸”ë¡œê·¸/ë‰´ìŠ¤/ê´‘ê³  ë“± ì„ì„ â†’ ìƒí˜¸ëª… ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ í•„í„°
        ratio = difflib.SequenceMatcher(None, title.lower(), name.lower()).ratio()
        if ratio >= 0.45 or name.lower() in title.lower():
            links.append(href)
            titles.append(title)
        if len(links) >= 3:
            break

    if not links:
        return None
    return {"title": titles[0], "link": links[0]}

# 4) OpenAIë¡œ â€œìš”ì•½/ì½”ë©˜íŠ¸â€ë§Œ ìƒì„± (ë¦¬ë­í¬ í—ˆìš©, ìƒˆ ê°€ê²Œ ìƒì„± ê¸ˆì§€)
SYS = """You summarize and lightly re-rank *existing* restaurant candidates.
Never invent new places. Output Korean, playful but concise."""

def ai_comment(cands, key):
    if not _openai_ok or not key or not cands:
        return None
    client = OpenAI(api_key=key)
    prompt = {
        "role":"user",
        "content":(
            "ì•„ë˜ í›„ë³´(ì´ë¦„/ì¶œì²˜/ê²€ì¦ë§í¬)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒìœ„ 5ê³³ ì´ë‚´ë¥¼ í•œ ì¤„ ìš”ì•½ê³¼ í•¨ê»˜ ì¶”ì²œí•´ì¤˜. "
            "ìƒˆ ê°€ê²Œë¥¼ ë§Œë“¤ì§€ ë§ê³ , ì£¼ì–´ì§„ í›„ë³´ë§Œ ì¬ì •ë ¬í•˜ê³  ì½”ë©˜íŠ¸ë¥¼ ë¶™ì—¬. "
            "JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´: [{name, reason, link}].\n\n" + json.dumps(cands, ensure_ascii=False)
        )
    }
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":SYS}, prompt],
            response_format={"type":"json_object"},
            temperature=0.3
        )
        data = json.loads(resp.choices[0].message.content)
        return data
    except Exception:
        return None

# ============== ì‹¤í–‰ ==============
if go:
    if not food.strip():
        st.warning("ìŒì‹ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”!")
        st.stop()

    rows = []
    # 1) Kakao ìš°ì„ 
    if KAKAO_KEY:
        with st.spinner("ì¹´ì¹´ì˜¤ì—ì„œ ì‹¤ë°ì´í„° ìˆ˜ì§‘ ì¤‘â€¦"):
            try:
                rows = kakao_search_places(KAKAO_KEY, gu, food, size=topk*2)
            except Exception as e:
                st.info(f"Kakao ìˆ˜ì§‘ ì‹¤íŒ¨(í‚¤/ì¿¼í„° ë¬¸ì œì¼ ìˆ˜ ìˆì–´ìš”): {e}")

    # 2) ì—†ìœ¼ë©´ OSM í›„ë³´
    if not rows:
        with st.spinner("í‚¤ ì—†ì´(ì˜¤í”ˆìŠ¤íŠ¸ë¦¬íŠ¸ë§µ) í›„ë³´ ìˆ˜ì§‘ ì¤‘â€¦"):
            try:
                rows = overpass_candidates(gu, food, size=topk)
            except Exception as e:
                st.error(f"í‚¤ ì—†ì´ í›„ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                st.stop()

    # 3) ë„¤ì´ë²„ ì›¹ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ í™•ì¸ + ë§í¬ ë¶€ì—¬
    verified = []
    with st.spinner("ë„¤ì´ë²„ ì›¹ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì¡´ ê²€ì¦ ì¤‘â€¦"):
        for r in rows:
            v = naver_web_validate(r["name"], gu, food)
            if v:
                r["verified_link"] = v["link"]
                r["verified_title"] = v["title"]
                verified.append(r)
            if len(verified) >= topk:
                break

    if not verified:
        st.info("ê²€ì¦ëœ ê²°ê³¼ê°€ ì—†ì–´ìš” ğŸ¥² í‚¤ì›Œë“œë¥¼ ë” ë„“ê²Œ ì ê±°ë‚˜ ë‹¤ë¥¸ êµ¬ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        st.stop()

    # 4) OpenAIë¡œ â€˜ìš”ì•½/ë¦¬ë­í¬â€™ (ì„ íƒ)
    summary = None
    if OPENAI_KEY:
        payload = [{"name": r["name"], "source": r["source"], "link": r.get("verified_link","")} for r in verified]
        ai = ai_comment(payload, OPENAI_KEY)
        if ai and isinstance(ai, dict):
            summary = ai

    # 5) ì¶œë ¥
    st.success(f"**{gu} Â· {food}** ì‹¤ê²€ìƒ‰ ê¸°ë°˜ ì¶”ì²œ TOP{len(verified)}")
    cols = ["name","road_address","address","phone","verified_title","verified_link"]
    show = pd.DataFrame([{k: v for k, v in r.items() if k in cols} for r in verified]) \
            .rename(columns={"name":"ìƒí˜¸ëª…","road_address":"ë„ë¡œëª…ì£¼ì†Œ","address":"ì§€ë²ˆì£¼ì†Œ",
                             "phone":"ì „í™”","verified_title":"ê²€ì¦ì œëª©","verified_link":"ê²€ì¦ë§í¬"})
    show.index = range(1, len(show)+1)
    st.dataframe(show, use_container_width=True)

    for r in verified:
        link = r.get("verified_link","#")
        title = r.get("verified_title","")
        st.markdown(f"**ğŸ½ï¸ {r['name']}**  Â·  [{title}]({link})")

    st.write("---")
    if summary and "items" in summary or isinstance(summary, list):
        st.subheader("ğŸ¤– ìš”ì•½ & ë¦¬ë­í¬ (AI)")
        try:
            items = summary.get("items", summary)  # ë‘˜ ì¤‘ í•˜ë‚˜ í˜•íƒœ
            for it in items[:topk]:
                st.markdown(f"- **{it.get('name','')}** â€” {it.get('reason','')}  ğŸ”— {it.get('link','')}")
        except Exception:
            pass

    # ë‹¤ìš´ë¡œë“œ
    csv = show.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", csv, file_name="realsearch_restaurants.csv", mime="text/csv", use_container_width=True)

else:
    st.info("êµ¬/í‚¤ì›Œë“œ/ê°œìˆ˜ ì •í•˜ê³  â€˜ì‹¤ì‹œê°„ìœ¼ë¡œ ì°¾ê¸°â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”! ê²°ê³¼ëŠ” ì‹¤ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œë§Œ ë³´ì—¬ë“œë ¤ìš” ğŸ™‚")
