import streamlit as st
import pandas as pd
import time
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import folium
from streamlit_folium import st_folium

st.set_page_config(page_title="ì‹ë‹¹ ì¶”ì²œ", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸœ ì‹ë‹¹ ì¶”ì²œ (ì„œìš¸) â€” MZ ê°ì„± ë²„ì „ âœ¨")
st.caption("ë„¤ì´ë²„ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì°¾ì•„ì˜¨ TOP5! ì§€ë„ë¥¼ í˜¸ë²„í•˜ë©´ ëŒ€í‘œë©”ë‰´/ê°€ê²©ë„ ìŠ¥~ ë³´ì—¬ì¤„ê²Œìš” ğŸ˜")

# ---------------------------------------
# ê³µìš© ì„¤ì •
# ---------------------------------------
SEOUL_GU = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬","ë…¸ì›êµ¬","ë„ë´‰êµ¬",
    "ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬","ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬",
    "ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]

EMOJI = {"ì‹ë‹¹":"ğŸ½ï¸","ì£¼ì†Œ":"ğŸ“","ì „í™”":"ğŸ“","í‰ì ":"â­ï¸","ë©”ë‰´":"ğŸ“‹","ë§í¬":"ğŸ”—"}

# ì„¸ì…˜ì—ì„œ ìŒì‹ ê¸°ë³¸ê°’ ì½ê¸°
default_food = st.session_state.get("selected_food", "")
colA, colB = st.columns([1,1])
with colA:
    gu = st.selectbox("ì„œìš¸ì‹œ **êµ¬**ë¥¼ ê³¨ë¼ì£¼ì„¸ìš”", SEOUL_GU, index=SEOUL_GU.index("ê°•ë‚¨êµ¬"))
with colB:
    food = st.text_input("ë¬´ìŠ¨ ìŒì‹ ì°¾ì„ê¹Œìš”? (ë©”ì¸ í˜ì´ì§€ ì„ íƒê°’ ìë™ ì—°ë™)", value=str(default_food) or "")

go = st.button("ğŸ” ì‹ë‹¹ ì°¾ê¸°")

st.write("---")

# ---------------------------------------
# ë„¤ì´ë²„ ë¡œì»¬ ê²€ìƒ‰ (ìƒìœ„ 5ê³³)
# ---------------------------------------
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"
}

def search_naver_local(gu: str, food: str, topk: int = 5):
    """
    ë„¤ì´ë²„ 'ì§€ì—­(where=local)' ê²°ê³¼ íŒŒì‹± (ê°€ë²¼ìš´ HTML íŒŒì„œ).
    ë°˜í™˜: [{name, address, phone, rating, url, menu_snippet}]
    """
    q = f"{gu} {food} ì‹ë‹¹"
    url = f"https://search.naver.com/search.naver?where=local&query={quote_plus(q)}"
    r = requests.get(url, headers=HEADERS, timeout=10)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "lxml")

    # ê²°ê³¼ ë¸”ë¡ í›„ë³´ë“¤: êµ¬ì¡°ê°€ ìì£¼ ë°”ë€Œë¯€ë¡œ ë„“ê²Œ íƒìƒ‰í•˜ê³  í‚¤ì›Œë“œë¡œ í•„í„°
    items = []
    # ë¦¬ìŠ¤íŠ¸í˜• ê²°ê³¼ ì¹´ë“œ aíƒœê·¸ í›„ë³´ ìˆ˜ì§‘
    for a in soup.select("a"):
        href = a.get("href", "")
        # ë„¤ì´ë²„í”Œë ˆì´ìŠ¤/ì§€ë„ ë§í¬ë§Œ ì„ ë³„
        if "map.naver.com" in href or "place.naver.com" in href:
            name = a.get_text(strip=True)
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê´‘ê³ /ë¶ˆí•„ìš” ë§í¬ ìŠ¤í‚µ
            if not name or len(name) < 2:
                continue
            items.append((name, href))

    # ìœ ë‹ˆí¬ë¡œ ì •ë¦¬
    seen = set()
    uniq = []
    for name, href in items:
        key = (name, href)
        if key in seen: 
            continue
        seen.add(key)
        uniq.append((name, href))

    # ì¶”ê°€ ì •ë³´(ì£¼ì†Œ/ì „í™”/í‰ì /ë©”ë‰´ ìŠ¤ë‹ˆí«) ì¶”ì¶œ: ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ íŒíŠ¸ë¥¼ ëª¨ì•„ë´„
    results = []
    for name, href in uniq:
        # ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì†Œ/í‰ì /ì „í™” í›„ë³´ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
        # ê°„ë‹¨íˆ nameì´ ë“¤ì–´ê°„ ì¸ì ‘ ë…¸ë“œë“¤ì„ ê²€ìƒ‰(ìœ ì—°í•œ ë°©ì‹)
        address = phone = rating = menu_snippet = ""
        # ì£¼ì†Œ íŒ¨í„´ íŒíŠ¸
        addr_candidates = soup.find_all(string=re.compile(r"(ì„œìš¸|ë™|ë¡œ|ê¸¸|êµ¬|ë²ˆì§€)"))
        if addr_candidates:
            address = str(addr_candidates[0]).strip()[:60]

        # í‰ì  í›„ë³´
        rating_candidates = soup.find_all(string=re.compile(r"í‰ì |ë¦¬ë·°|ë³„|[0-9]\.?[0-9]\s*/\s*5"))
        if rating_candidates:
            rating = re.findall(r"([0-9]\.?[0-9])\s*/\s*5", rating_candidates[0])
            rating = rating[0] if rating else rating_candidates[0].strip()[:20]

        # ì „í™” í›„ë³´
        phone_candidates = soup.find_all(string=re.compile(r"0\d{1,2}-\d{3,4}-\d{4}"))
        if phone_candidates:
            phone = phone_candidates[0].strip()

        # ë©”ë‰´/ê°€ê²© ìŠ¤ë‹ˆí« í›„ë³´
        menu_candidates = soup.find_all(string=re.compile(r"(ë©”ë‰´|ê°€ê²©|ëŒ€í‘œë©”ë‰´|ì›)"))
        if menu_candidates:
            menu_snippet = str(menu_candidates[0]).strip()[:60]

        results.append({
            "name": name,
            "address": address,
            "phone": phone,
            "rating": rating,
            "url": href
        })
        # ìƒìœ„ topkë§Œ
        if len(results) >= topk:
            break

    return results

# ---------------------------------------
# ì§€ì˜¤ì½”ë”© (OSM Nominatim)
# ---------------------------------------
@st.cache_data(show_spinner=False)
def geocode_many(rows, gu):
    geolocator = Nominatim(user_agent="food-drink-pairing-app")
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
    coords = []
    for r in rows:
        # ì£¼ì†Œê°€ ë„ˆë¬´ ë¹ˆì•½í•˜ë©´ "ì„œìš¸ {êµ¬} {ìƒí˜¸}"ë¡œ ì§€ì˜¤ì½”ë”© ì‹œë„
        query = r["address"] or f"ì„œìš¸ {gu} {r['name']}"
        try:
            loc = geocode(query)
            if loc:
                coords.append((loc.latitude, loc.longitude))
            else:
                coords.append((None, None))
        except Exception:
            coords.append((None, None))
        time.sleep(0.1)
    return coords

def build_tooltip_html(row):
    name = row["name"]
    addr = row.get("address") or "ì£¼ì†Œ ì •ë³´ ì¤€ë¹„ì¤‘"
    phone = row.get("phone") or "ë²ˆí˜¸ ì •ë³´ ì—†ìŒ"
    rating = row.get("rating") or "-"
    url = row.get("url") or "#"

    html = f"""
    <div style="font-size:14px; line-height:1.5">
      <div style="font-weight:700">{EMOJI['ì‹ë‹¹']} {name}</div>
      <div>{EMOJI['ì£¼ì†Œ']} {addr}</div>
      <div>{EMOJI['ì „í™”']} {phone}</div>
      <div>{EMOJI['í‰ì ']} {rating}</div>
      <div>{EMOJI['ë§í¬']} <a href="{url}" target="_blank">ë„¤ì´ë²„ ìƒì„¸</a></div>
      <div style="margin-top:6px; color:#666">â€» ëŒ€í‘œë©”ë‰´/ê°€ê²©ì€ ë„¤ì´ë²„ ìƒì„¸í˜ì´ì§€ì—ì„œ í™•ì¸ì´ ë” ì •í™•í•´ìš”!</div>
    </div>
    """
    return html

# ---------------------------------------
# ì‹¤í–‰
# ---------------------------------------
if go:
    if not food.strip():
        st.warning("ìŒì‹ëª…ì„ ì…ë ¥í•´ì¤˜ìš”! ì˜ˆ: ê¹€ì¹˜ë³¶ìŒë°¥, ë¹„ë¹”ë°¥ ë“± ğŸ™‚")
        st.stop()

    with st.spinner("ë„¤ì´ë²„ì— ë¬¼ì–´ë³´ê³  ìˆì–´ìš”â€¦ (ì¡°ê¸ˆë§Œ!)"):
        rows = search_naver_local(gu, food, topk=5)

    if not rows:
        st.info("ì•—, ê²°ê³¼ê°€ ì—†ë„¤ìš”. ìŒì‹ëª…ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ë³¼ê¹Œìš”? ì˜ˆ: ë¹„ë¹”ë°¥ â†’ ì „ì£¼ë¹„ë¹”ë°¥")
        st.stop()

    df = pd.DataFrame(rows)
    st.success(f"**{gu}**ì—ì„œ **{food}** íŒŒëŠ” ê³³ TOP5 ë½‘ì•„ì™”ì–´ìš”! ğŸ™Œ")
    st.dataframe(df[["name","address","phone","rating","url"]].rename(
        columns={"name":"ìƒí˜¸ëª…","address":"ì£¼ì†Œ","phone":"ì „í™”","rating":"í‰ì ","url":"ë§í¬"}
    ), use_container_width=True)

    # ì§€ë„ ë§Œë“¤ê¸°
    coords = geocode_many(rows, gu)
    for i, (lat, lon) in enumerate(coords):
        rows[i]["lat"] = lat
        rows[i]["lon"] = lon

    # ì¤‘ì‹¬ ì¢Œí‘œ
    center_lat = next((r["lat"] for r in rows if r["lat"]), 37.5665)
    center_lon = next((r["lon"] for r in rows if r["lon"]), 126.9780)

    m = folium.Map(location=[center_lat, center_lon], zoom_start=13, tiles="CartoDB positron")

    for r in rows:
        if not r["lat"] or not r["lon"]:
            continue
        tooltip_html = build_tooltip_html(r)  # hover ì‹œ ë³´ì—¬ì¤„ ë‚´ìš©
        folium.Marker(
            location=[r["lat"], r["lon"]],
            tooltip=folium.Tooltip(tooltip_html, sticky=True),  # â† í˜¸ë²„ íˆ´íŒ
            popup=folium.Popup(tooltip_html, max_width=300),
            icon=folium.Icon(color="red", icon="cutlery", prefix="fa")
        ).add_to(m)

    st_folium(m, width=None, height=520)
    st.caption("Tip) ì¥ì†Œë¥¼ íƒ­í•˜ë©´ íŒì—…ìœ¼ë¡œë„ ì •ë³´ê°€ ë– ìš”. ë§í¬ ëˆŒëŸ¬ì„œ ë°”ë¡œ ë„¤ì´ë²„ ë””í…Œì¼ GO! ğŸ’¨")

else:
    st.info("ì™¼ìª½ì—ì„œ **êµ¬**ë‘ **ìŒì‹** ì •í•˜ê³ , ìœ„ì˜ **ê²€ìƒ‰** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”! ğŸš€")
